{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sunethjayawardana/spam-classification-pyspark?scriptVersionId=160391430\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"5b5cce1b","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-25T13:49:29.452152Z","iopub.status.busy":"2024-01-25T13:49:29.451611Z","iopub.status.idle":"2024-01-25T13:49:30.519203Z","shell.execute_reply":"2024-01-25T13:49:30.517882Z"},"papermill":{"duration":1.078944,"end_time":"2024-01-25T13:49:30.522162","exception":false,"start_time":"2024-01-25T13:49:29.443218","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/spam-or-not-spam-dataset/spam_or_not_spam.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"4b34c66c","metadata":{"papermill":{"duration":0.005623,"end_time":"2024-01-25T13:49:30.536183","exception":false,"start_time":"2024-01-25T13:49:30.53056","status":"completed"},"tags":[]},"source":["# This notebook is about building a spam classification using PySpark. Depending on the text the model can predict it as spam or not. The model uses NLP tool kit for predictions."]},{"cell_type":"code","execution_count":2,"id":"b6ba6f38","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:49:30.551823Z","iopub.status.busy":"2024-01-25T13:49:30.551003Z","iopub.status.idle":"2024-01-25T13:50:26.417243Z","shell.execute_reply":"2024-01-25T13:50:26.415755Z"},"papermill":{"duration":55.876819,"end_time":"2024-01-25T13:50:26.419938","exception":false,"start_time":"2024-01-25T13:49:30.543119","status":"completed"},"tags":[]},"outputs":[],"source":["#Installing PySpark \n","!pip install pyspark --quiet"]},{"cell_type":"markdown","id":"1e7e74dc","metadata":{"papermill":{"duration":0.005556,"end_time":"2024-01-25T13:50:26.431639","exception":false,"start_time":"2024-01-25T13:50:26.426083","status":"completed"},"tags":[]},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":3,"id":"04672bc5","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:26.44573Z","iopub.status.busy":"2024-01-25T13:50:26.445315Z","iopub.status.idle":"2024-01-25T13:50:27.066436Z","shell.execute_reply":"2024-01-25T13:50:27.06524Z"},"papermill":{"duration":0.631812,"end_time":"2024-01-25T13:50:27.06942","exception":false,"start_time":"2024-01-25T13:50:26.437608","status":"completed"},"tags":[]},"outputs":[],"source":["#Apache Spark Libraries\n","import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, split, when\n","from pyspark.ml.feature import VectorAssembler\n","# Import the Decision Tree Classifier class\n","from pyspark.ml.classification  import DecisionTreeClassifier\n","# Import the logistic regression class\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n","from pyspark.sql.functions import regexp_replace\n","from pyspark.ml import Pipeline"]},{"cell_type":"markdown","id":"b80d84c8","metadata":{"papermill":{"duration":0.005566,"end_time":"2024-01-25T13:50:27.080991","exception":false,"start_time":"2024-01-25T13:50:27.075425","status":"completed"},"tags":[]},"source":["# Build Spark Session"]},{"cell_type":"code","execution_count":4,"id":"ee9b1021","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:27.09443Z","iopub.status.busy":"2024-01-25T13:50:27.094019Z","iopub.status.idle":"2024-01-25T13:50:33.594797Z","shell.execute_reply":"2024-01-25T13:50:33.593674Z"},"papermill":{"duration":6.510713,"end_time":"2024-01-25T13:50:33.597467","exception":false,"start_time":"2024-01-25T13:50:27.086754","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/01/25 13:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]},{"data":{"text/plain":["'3.5.0'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Building Spark Session\n","spark = (SparkSession.builder\n","                  .appName('flight')\n","                  .config(\"spark.executor.memory\", \"1G\")\n","                  .config(\"spark.executor.cores\",\"4\")\n","                  .getOrCreate())\n","\n","spark.sparkContext.setLogLevel('WARN')\n","spark.version"]},{"cell_type":"markdown","id":"1b0e0f2f","metadata":{"papermill":{"duration":0.005918,"end_time":"2024-01-25T13:50:33.609724","exception":false,"start_time":"2024-01-25T13:50:33.603806","status":"completed"},"tags":[]},"source":["# Load Data"]},{"cell_type":"code","execution_count":5,"id":"c48da4d3","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:33.626772Z","iopub.status.busy":"2024-01-25T13:50:33.625686Z","iopub.status.idle":"2024-01-25T13:50:43.442533Z","shell.execute_reply":"2024-01-25T13:50:43.44138Z"},"papermill":{"duration":9.82915,"end_time":"2024-01-25T13:50:43.446065","exception":false,"start_time":"2024-01-25T13:50:33.616915","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["The data contain 3000 records.\n","+--------------------+-----+\n","|               email|label|\n","+--------------------+-----+\n","| date wed NUMBER ...|    0|\n","|martin a posted t...|    0|\n","|man threatens exp...|    0|\n","|klez the virus th...|    0|\n","| in adding cream ...|    0|\n","+--------------------+-----+\n","only showing top 5 rows\n","\n","[('email', 'string'), ('label', 'int')]\n"]},{"data":{"text/plain":["3000"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Read data from CSV file\n","spam = spark.read.csv('/kaggle/input/spam-or-not-spam-dataset/spam_or_not_spam.csv',\n","                         sep=',',\n","                         header=True,\n","                         inferSchema=True,\n","                         nullValue='NA')\n","\n","# Get number of records\n","print(\"The data contain %d records.\" % spam.count())\n","\n","# View the first five records\n","spam.show(5)\n","\n","# Check column data types\n","print(spam.dtypes)\n","spam.count()"]},{"cell_type":"code","execution_count":6,"id":"c289208a","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:43.467643Z","iopub.status.busy":"2024-01-25T13:50:43.467112Z","iopub.status.idle":"2024-01-25T13:50:43.581396Z","shell.execute_reply":"2024-01-25T13:50:43.58018Z"},"papermill":{"duration":0.129993,"end_time":"2024-01-25T13:50:43.585541","exception":false,"start_time":"2024-01-25T13:50:43.455548","status":"completed"},"tags":[]},"outputs":[],"source":["# Drop rows with missing email values\n","spam = spam.dropna(subset=['email'])\n","# Remove punctuation (REGEX provided) and numbers\n","wrangled = spam.withColumn('email', regexp_replace(spam.email, '[_():;,.!?\\\\-]', ' '))\n","wrangled = wrangled.withColumn('email', regexp_replace(wrangled.email, '[0-9]', ' '))\n","\n","# Merge multiple spaces\n","wrangled = wrangled.withColumn('email', regexp_replace(wrangled.email, ' +', ' '))"]},{"cell_type":"code","execution_count":7,"id":"6462ff16","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:43.604968Z","iopub.status.busy":"2024-01-25T13:50:43.604573Z","iopub.status.idle":"2024-01-25T13:50:44.027426Z","shell.execute_reply":"2024-01-25T13:50:44.025285Z"},"papermill":{"duration":0.436346,"end_time":"2024-01-25T13:50:44.031173","exception":false,"start_time":"2024-01-25T13:50:43.594827","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+-----+\n","|               email|label|\n","+--------------------+-----+\n","| date wed NUMBER ...|    0|\n","|martin a posted t...|    0|\n","|man threatens exp...|    0|\n","|klez the virus th...|    0|\n","| in adding cream ...|    0|\n","| i just had to ju...|    0|\n","|the scotsman NUMB...|    0|\n","|martin adamson wr...|    0|\n","|the scotsman thu ...|    0|\n","|i have been tryin...|    0|\n","|hello have you se...|    0|\n","|yes great minds t...|    0|\n","|on mon aug NUMBER...|    0|\n","| from chris garri...|    0|\n","|spamassassin is h...|    0|\n","|hi all apologies ...|    0|\n","| in forteana y d ...|    0|\n","|in a nutshell sol...|    0|\n","|apols if this has...|    0|\n","|can someone expla...|    0|\n","+--------------------+-----+\n","only showing top 20 rows\n","\n"]}],"source":["wrangled.show()"]},{"cell_type":"markdown","id":"90056e85","metadata":{"papermill":{"duration":0.009357,"end_time":"2024-01-25T13:50:44.050006","exception":false,"start_time":"2024-01-25T13:50:44.040649","status":"completed"},"tags":[]},"source":["# Initiating Pipeline\n","* split the text into tokens\n","* remove stop words\n","* applie the hashing trick\n","* convert the data from counts to IDF\n","* train a logistic regression model."]},{"cell_type":"code","execution_count":8,"id":"f057580c","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:44.071676Z","iopub.status.busy":"2024-01-25T13:50:44.07118Z","iopub.status.idle":"2024-01-25T13:50:44.36599Z","shell.execute_reply":"2024-01-25T13:50:44.365069Z"},"papermill":{"duration":0.308745,"end_time":"2024-01-25T13:50:44.368744","exception":false,"start_time":"2024-01-25T13:50:44.059999","status":"completed"},"tags":[]},"outputs":[],"source":["# Break text into tokens at non-word characters\n","tokenizer = Tokenizer(inputCol='email', outputCol='words')\n","\n","# Remove stop words\n","remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n","\n","# Apply the hashing trick and transform to TF-IDF\n","hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\")\n","idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n","\n","# Create a logistic regression object and add everything to a pipeline\n","logistic = LogisticRegression(featuresCol=idf.getOutputCol(),labelCol=\"label\")\n","pipeline = Pipeline(stages=[tokenizer, remover, hasher,  idf, logistic])"]},{"cell_type":"code","execution_count":9,"id":"0ee412ab","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:50:44.385049Z","iopub.status.busy":"2024-01-25T13:50:44.383916Z","iopub.status.idle":"2024-01-25T13:51:10.936539Z","shell.execute_reply":"2024-01-25T13:51:10.935357Z"},"papermill":{"duration":26.564762,"end_time":"2024-01-25T13:51:10.940485","exception":false,"start_time":"2024-01-25T13:50:44.375723","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["24/01/25 13:50:51 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n","24/01/25 13:50:54 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:57 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:57 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:58 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:58 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:58 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:59 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:59 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:59 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:50:59 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:00 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:00 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:00 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:00 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:00 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:01 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:01 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:01 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:01 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:01 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:02 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:02 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:02 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:02 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:02 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:03 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:04 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:07 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:09 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:09 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:09 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:09 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:09 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","24/01/25 13:51:09 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"]}],"source":["train_data, test_data = wrangled.randomSplit([0.8, 0.2])\n","model = pipeline.fit(train_data)"]},{"cell_type":"code","execution_count":10,"id":"8f170c18","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:51:10.978001Z","iopub.status.busy":"2024-01-25T13:51:10.976765Z","iopub.status.idle":"2024-01-25T13:51:11.269322Z","shell.execute_reply":"2024-01-25T13:51:11.268128Z"},"papermill":{"duration":0.315003,"end_time":"2024-01-25T13:51:11.272537","exception":false,"start_time":"2024-01-25T13:51:10.957534","status":"completed"},"tags":[]},"outputs":[],"source":["predictions = model.transform(test_data)"]},{"cell_type":"code","execution_count":11,"id":"e10dfa2a","metadata":{"execution":{"iopub.execute_input":"2024-01-25T13:51:11.312142Z","iopub.status.busy":"2024-01-25T13:51:11.311491Z","iopub.status.idle":"2024-01-25T13:51:13.381322Z","shell.execute_reply":"2024-01-25T13:51:13.380045Z"},"papermill":{"duration":2.099598,"end_time":"2024-01-25T13:51:13.384265","exception":false,"start_time":"2024-01-25T13:51:11.284667","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["24/01/25 13:51:11 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Area Under ROC: 0.9931213395699843\n"]}],"source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n","area_under_curve = evaluator.evaluate(predictions)\n","print(\"Area Under ROC:\", area_under_curve)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":91827,"sourceId":213216,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":111.245636,"end_time":"2024-01-25T13:51:16.019602","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-25T13:49:24.773966","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}